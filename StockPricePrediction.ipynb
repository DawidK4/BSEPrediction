{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85e1da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns \n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf \n",
    "\n",
    "import yfinance as yf "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be3d1a3",
   "metadata": {},
   "source": [
    "#    Fetching the stock data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f7266",
   "metadata": {},
   "source": [
    "Price and volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85716bd8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "data = yf.Ticker(\"AAPL\")\n",
    "\n",
    "ohlc = data.history(period=\"max\", interval=\"1d\")[['Open', 'High', 'Low', 'Close', 'Volume']]\n",
    "ohlc.index = ohlc.index.tz_localize(None)  # Make index timezone-naive\n",
    "volume = ohlc['Volume']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8068c97",
   "metadata": {},
   "source": [
    "Latest quaterly financials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773d0331",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\yfinance\\scrapers\\fundamentals.py:36: DeprecationWarning: 'Ticker.earnings' is deprecated as not available via API. Look for \"Net Income\" in Ticker.income_stmt.\n",
      "  warnings.warn(\"'Ticker.earnings' is deprecated as not available via API. Look for \\\"Net Income\\\" in Ticker.income_stmt.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "dividends = data.dividends\n",
    "splits = data.splits\n",
    "actions = data.actions\n",
    "capital_gains = data.capital_gains\n",
    "\n",
    "income_stmt = data.income_stmt\n",
    "balance_sheet = data.balance_sheet\n",
    "cashflow = data.cash_flow\n",
    "tmm_cashflow = data.ttm_cash_flow\n",
    "earnings = data.earnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6be230e",
   "metadata": {},
   "source": [
    "Additional data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cd59f2b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "info = data.info\n",
    "fast_info = data.fast_info\n",
    "calendar = data.calendar\n",
    "earnings_dates = data.earnings_dates\n",
    "# sec_fillings = data.sec_fillings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c17ab24",
   "metadata": {},
   "source": [
    "Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d496ce93",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "recommendations = data.recommendations\n",
    "recommendations_summary = data.recommendations_summary\n",
    "\n",
    "upgrades_downgrades = data.upgrades_downgrades\n",
    "sustainability = data.sustainability\n",
    "\n",
    "analyst_price_targets = data.analyst_price_targets\n",
    "earnings_estimate = data.earnings_estimate\n",
    "revenue_estimate = data.revenue_estimate\n",
    "\n",
    "earnings_history = data.earnings_history\n",
    "eps_trend = data.eps_trend\n",
    "# eps_revision = data.eps_revision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ab4464",
   "metadata": {},
   "source": [
    "Holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "045fb037",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "funds_data = data.funds_data\n",
    "insider_purchases = data.insider_purchases\n",
    "insider_transactions = data.insider_transactions\n",
    "insider_roster_holders = data.insider_roster_holders\n",
    "major_holders = data.major_holders\n",
    "# institutional_holder = data.institutional_holder\n",
    "mutualfund_holders = data.mutualfund_holders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bdb7be",
   "metadata": {},
   "source": [
    "# Fetching the market data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c33a165",
   "metadata": {},
   "outputs": [],
   "source": [
    "us_market = yf.Market('US')\n",
    "gb_market = yf.Market('GB')\n",
    "\n",
    "asian_market = yf.Market('ASIA')\n",
    "european_market = yf.Market('EUROPE')\n",
    "\n",
    "rates = yf.Market('RATES')\n",
    "commodities = yf.Market('COMMODITIES')\n",
    "currencies = yf.Market('CURRENCIES')\n",
    "crypto = yf.Market('CRYPTOCURRENCIES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25d4713",
   "metadata": {},
   "source": [
    "# Sector and industry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be071929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<property object at 0x000001887863FDD0>\n"
     ]
    }
   ],
   "source": [
    "print(yf.Sector.industries) # to be continued"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e97fe2a7",
   "metadata": {},
   "source": [
    "# Data cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d01bd2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_dividend_through_years = dividends.sum()\n",
    "total_number_of_stock_splits = len(splits)\n",
    "# Process capital gains "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8ad68",
   "metadata": {},
   "source": [
    "Financial statement transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a7d4452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:12: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:18: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_income.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:18: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_income.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:27: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:32: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_balance.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_balance.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:46: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:41: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:46: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  aligned_cashflow.fillna(method='ffill', inplace=True)\n",
      "C:\\Users\\dawid\\AppData\\Local\\Temp\\ipykernel_19844\\2446286178.py:46: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  aligned_cashflow.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "final_df = pd.DataFrame(index=ohlc.index)\n",
    "\n",
    "# Income Statement\n",
    "income_stmt = data.financials.T  # Transpose so each row is a report\n",
    "income_stmt.index = pd.to_datetime(income_stmt.index)  # Ensure datetime index\n",
    "\n",
    "income_stmt_sorted = income_stmt.sort_index()\n",
    "aligned_income = pd.DataFrame(index=ohlc.index, columns=income_stmt.columns)\n",
    "\n",
    "for report_date in income_stmt_sorted.index:\n",
    "    mask = (aligned_income.index >= report_date)\n",
    "    aligned_income.loc[mask] = aligned_income.loc[mask].fillna(method='ffill')\n",
    "    aligned_income.loc[aligned_income.index >= report_date] = \\\n",
    "    pd.DataFrame([income_stmt.loc[report_date].values] * len(aligned_income.loc[aligned_income.index >= report_date]),\n",
    "                 index=aligned_income.loc[aligned_income.index >= report_date].index,\n",
    "                 columns=aligned_income.columns)\n",
    "    \n",
    "aligned_income.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Balance Sheet\n",
    "balance_sheet = data.balance_sheet.T\n",
    "balance_sheet.index = pd.to_datetime(balance_sheet.index)\n",
    "balance_sheet_sorted = balance_sheet.sort_index()\n",
    "aligned_balance = pd.DataFrame(index=ohlc.index, columns=balance_sheet.columns)\n",
    "for report_date in balance_sheet_sorted.index:\n",
    "    mask = (aligned_balance.index >= report_date)\n",
    "    aligned_balance.loc[mask] = aligned_balance.loc[mask].fillna(method='ffill')\n",
    "    aligned_balance.loc[aligned_balance.index >= report_date] = \\\n",
    "        pd.DataFrame([balance_sheet.loc[report_date].values] * len(aligned_balance.loc[aligned_balance.index >= report_date]),\n",
    "                     index=aligned_balance.loc[aligned_balance.index >= report_date].index,\n",
    "                     columns=aligned_balance.columns)\n",
    "aligned_balance.fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Cash Flow\n",
    "cashflow = data.cashflow.T\n",
    "cashflow.index = pd.to_datetime(cashflow.index)\n",
    "cashflow_sorted = cashflow.sort_index()\n",
    "aligned_cashflow = pd.DataFrame(index=ohlc.index, columns=cashflow.columns)\n",
    "for report_date in cashflow_sorted.index:\n",
    "    mask = (aligned_cashflow.index >= report_date)\n",
    "    aligned_cashflow.loc[mask] = aligned_cashflow.loc[mask].fillna(method='ffill')\n",
    "    aligned_cashflow.loc[aligned_cashflow.index >= report_date] = \\\n",
    "        pd.DataFrame([cashflow.loc[report_date].values] * len(aligned_cashflow.loc[aligned_cashflow.index >= report_date]),\n",
    "                     index=aligned_cashflow.loc[aligned_cashflow.index >= report_date].index,\n",
    "                     columns=aligned_cashflow.columns)\n",
    "aligned_cashflow.fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72885d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividends\n",
    "# Align dividends to ohlc index (ensure both indexes are timezone-naive)\n",
    "dividends = data.dividends.copy()\n",
    "dividends.index = dividends.index.tz_localize(None)\n",
    "aligned_dividends = pd.DataFrame(index=ohlc.index)\n",
    "aligned_dividends['Dividends'] = dividends.reindex(ohlc.index, method='ffill').fillna(0)\n",
    "\n",
    "# Splits\n",
    "# Align splits to ohlc index (ensure both indexes are timezone-naive)\n",
    "splits = data.splits.copy()\n",
    "splits.index = splits.index.tz_localize(None)\n",
    "aligned_splits = pd.DataFrame(index=ohlc.index)\n",
    "aligned_splits['Splits'] = splits.reindex(ohlc.index, method='ffill').fillna(0)\n",
    "\n",
    "# Combine all dataframes\n",
    "combined_df = pd.concat([ohlc, aligned_income, aligned_balance, aligned_cashflow, aligned_dividends, aligned_splits], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7e23a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open', 'High', 'Low', 'Close', 'Volume', 'Tax Effect Of Unusual Items',\n",
       "       'Tax Rate For Calcs', 'Normalized EBITDA',\n",
       "       'Net Income From Continuing Operation Net Minority Interest',\n",
       "       'Reconciled Depreciation',\n",
       "       ...\n",
       "       'Changes In Account Receivables', 'Other Non Cash Items',\n",
       "       'Stock Based Compensation', 'Deferred Tax', 'Deferred Income Tax',\n",
       "       'Depreciation Amortization Depletion', 'Depreciation And Amortization',\n",
       "       'Net Income From Continuing Operations', 'Dividends', 'Splits'],\n",
       "      dtype='object', length=167)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d716af8",
   "metadata": {},
   "source": [
    "Add features like technical indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8eb8edf",
   "metadata": {},
   "source": [
    "# Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b8de81",
   "metadata": {},
   "source": [
    "Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911068cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Mean Squared Error: 1.44\n",
      "Linear Regression R^2 Score: 1.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr_regressor = LinearRegression()\n",
    "lr_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lr_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Linear Regression Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Linear Regression R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59311d1f",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d42ea45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 3.76\n",
      "R^2 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "\n",
    "X = model_df.drop(columns=[\"Close\"])  \n",
    "y = model_df[\"Close\"] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=42)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075ddbaf",
   "metadata": {},
   "source": [
    "Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aca0e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Mean Squared Error: 2.89\n",
      "Random Forest R^2 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Random Forest Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Random Forest R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196be3f",
   "metadata": {},
   "source": [
    "XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70b3b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Mean Squared Error: 4.15\n",
      "XGBoost R^2 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgb_regressor = XGBRegressor(n_estimators=100, random_state=42, verbosity=0)\n",
    "xgb_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = xgb_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"XGBoost Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"XGBoost R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cda16b",
   "metadata": {},
   "source": [
    "Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ce170d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Mean Squared Error: 592.69\n",
      "SVR R^2 Score: -0.04\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svr_regressor = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=.1)\n",
    "svr_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svr_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"SVR Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"SVR R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316f3d59",
   "metadata": {},
   "source": [
    "K-Nearest Neighbors Regression (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4c686210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Mean Squared Error: 306.47\n",
      "KNN R^2 Score: 0.46\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"KNN Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"KNN R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8e7d63",
   "metadata": {},
   "source": [
    "LightGBM Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "23c09952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000295 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 852\n",
      "[LightGBM] [Info] Number of data points in the train set: 326, number of used features: 143\n",
      "[LightGBM] [Info] Start training from score 206.940897\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "LightGBM Mean Squared Error: 4.55\n",
      "LightGBM R^2 Score: 0.99\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "lgbm_regressor = LGBMRegressor(n_estimators=100, random_state=42)\n",
    "lgbm_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = lgbm_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"LightGBM Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"LightGBM R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2f552",
   "metadata": {},
   "source": [
    "Neural Network Regression (MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb3731be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP Mean Squared Error: 3095788080995789.00\n",
      "MLP R^2 Score: -5410105662364.31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "mlp_regressor = MLPRegressor(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42)\n",
    "mlp_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = mlp_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MLP Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"MLP R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7eb3d47",
   "metadata": {},
   "source": [
    "LSTM Neural Network Regression (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d1e58a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "LSTM Mean Squared Error: 29.34\n",
      "LSTM R^2 Score: 0.95\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step\n",
      "LSTM Mean Squared Error: 29.34\n",
      "LSTM R^2 Score: 0.95\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y.values.reshape(-1, 1))\n",
    "\n",
    "# Reshape for LSTM: (samples, timesteps, features)\n",
    "# We'll use a window of 1 (no lookback)\n",
    "X_lstm = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lstm, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(50, input_shape=(X_lstm.shape[1], X_lstm.shape[2])),\n",
    "    Dense(1)\n",
    "])\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "y_pred_scaled = model.predict(X_test)\n",
    "y_pred = scaler_y.inverse_transform(y_pred_scaled)\n",
    "y_test_inv = scaler_y.inverse_transform(y_test)\n",
    "\n",
    "mse = mean_squared_error(y_test_inv, y_pred)\n",
    "r2 = r2_score(y_test_inv, y_pred)\n",
    "\n",
    "print(f\"LSTM Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"LSTM R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa03c729",
   "metadata": {},
   "source": [
    "ARIMA/SARIMA Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de36fa1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'The `start` argument could not be matched to a location related to the index of the data.'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:609\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2606\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:2630\u001b[39m, in \u001b[36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 1737417600000000000",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:577\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:611\u001b[39m, in \u001b[36mpandas._libs.index.DatetimeEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2025-01-21 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:630\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    629\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mIndex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2025-01-21 00:00:00')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:249\u001b[39m, in \u001b[36mget_index_label_loc\u001b[39m\u001b[34m(key, index, row_labels)\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, (\u001b[38;5;28mint\u001b[39m, np.integer)):\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     loc = \u001b[43mrow_labels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:632\u001b[39m, in \u001b[36mDatetimeIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    631\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m632\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(orig_key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: Timestamp('2025-01-21 00:00:00')",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:358\u001b[39m, in \u001b[36mget_prediction_index\u001b[39m\u001b[34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m358\u001b[39m     start, _, start_oos = \u001b[43mget_index_label_loc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrow_labels\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:281\u001b[39m, in \u001b[36mget_index_label_loc\u001b[39m\u001b[34m(key, index, row_labels)\u001b[39m\n\u001b[32m    280\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m281\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m loc, index, index_was_expanded\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:245\u001b[39m, in \u001b[36mget_index_label_loc\u001b[39m\u001b[34m(key, index, row_labels)\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m     loc, index, index_was_expanded = \u001b[43mget_index_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:195\u001b[39m, in \u001b[36mget_index_loc\u001b[39m\u001b[34m(key, index)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mIndexError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m195\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[32m    196\u001b[39m loc = key\n",
      "\u001b[31mKeyError\u001b[39m: 'only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m model_fit = model.fit(disp=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Forecast\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m forecast = \u001b[43mmodel_fit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m mse = mean_squared_error(test, forecast)\n\u001b[32m     21\u001b[39m r2 = r2_score(test, forecast)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\base\\wrapper.py:113\u001b[39m, in \u001b[36mmake_wrapper.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m     obj = data.wrap_output(func(results, *args, **kwargs), how[\u001b[32m0\u001b[39m], how[\u001b[32m1\u001b[39m:])\n\u001b[32m    112\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m how:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     obj = data.wrap_output(\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m, how)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3488\u001b[39m, in \u001b[36mMLEResults.predict\u001b[39m\u001b[34m(self, start, end, dynamic, information_set, signal_only, **kwargs)\u001b[39m\n\u001b[32m   3423\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3424\u001b[39m \u001b[33;03mIn-sample prediction and out-of-sample forecasting\u001b[39;00m\n\u001b[32m   3425\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   3485\u001b[39m \u001b[33;03m    including confidence intervals.\u001b[39;00m\n\u001b[32m   3486\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3487\u001b[39m \u001b[38;5;66;03m# Perform the prediction\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3488\u001b[39m prediction_results = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_prediction\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdynamic\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minformation_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43minformation_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3490\u001b[39m \u001b[43m    \u001b[49m\u001b[43msignal_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43msignal_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3491\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m prediction_results.predicted_mean\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\statespace\\mlemodel.py:3341\u001b[39m, in \u001b[36mMLEResults.get_prediction\u001b[39m\u001b[34m(self, start, end, dynamic, information_set, signal_only, index, exog, extend_model, extend_kwargs, **kwargs)\u001b[39m\n\u001b[32m   3337\u001b[39m     start = \u001b[32m0\u001b[39m\n\u001b[32m   3339\u001b[39m \u001b[38;5;66;03m# Handle start, end, dynamic\u001b[39;00m\n\u001b[32m   3340\u001b[39m start, end, out_of_sample, prediction_index = (\n\u001b[32m-> \u001b[39m\u001b[32m3341\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_prediction_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   3343\u001b[39m \u001b[38;5;66;03m# Handle `dynamic`\u001b[39;00m\n\u001b[32m   3344\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dynamic, (\u001b[38;5;28mstr\u001b[39m, dt.datetime, pd.Timestamp)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837\u001b[39m, in \u001b[36mTimeSeriesModel._get_prediction_index\u001b[39m\u001b[34m(self, start, end, index, silent)\u001b[39m\n\u001b[32m    781\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    782\u001b[39m \u001b[33;03mGet the location of a specific key in an index or model row labels\u001b[39;00m\n\u001b[32m    783\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    834\u001b[39m \u001b[33;03msince we have required them to be full indexes, there is no ambiguity).\u001b[39;00m\n\u001b[32m    835\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    836\u001b[39m nobs = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.endog)\n\u001b[32m--> \u001b[39m\u001b[32m837\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_prediction_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_index\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_none\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_generated\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_index_generated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dawid\\Desktop\\BSEPrediction\\.venv\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:362\u001b[39m, in \u001b[36mget_prediction_index\u001b[39m\u001b[34m(start, end, nobs, base_index, index, silent, index_none, index_generated, data)\u001b[39m\n\u001b[32m    358\u001b[39m     start, _, start_oos = get_index_label_loc(\n\u001b[32m    359\u001b[39m         start, base_index, data.row_labels\n\u001b[32m    360\u001b[39m     )\n\u001b[32m    361\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m    363\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe `start` argument could not be matched to a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    364\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m location related to the index of the data.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    365\u001b[39m     )\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    367\u001b[39m     end = \u001b[38;5;28mmax\u001b[39m(start, \u001b[38;5;28mlen\u001b[39m(base_index) - \u001b[32m1\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'The `start` argument could not be matched to a location related to the index of the data.'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Use only the 'Close' price for time series forecasting\n",
    "model_df = combined_df.dropna()\n",
    "close_series = model_df['Close']\n",
    "\n",
    "# Split into train and test sets (time series split, no shuffling)\n",
    "split_idx = int(len(close_series) * 0.8)\n",
    "train, test = close_series.iloc[:split_idx], close_series.iloc[split_idx:]\n",
    "\n",
    "# Fit SARIMA model (simple order, can be tuned)\n",
    "model = SARIMAX(train, order=(1,1,1), seasonal_order=(1,1,1,12))\n",
    "model_fit = model.fit(disp=False)\n",
    "\n",
    "# Forecast\n",
    "forecast = model_fit.predict(start=test.index[0], end=test.index[-1], dynamic=False)\n",
    "\n",
    "mse = mean_squared_error(test, forecast)\n",
    "r2 = r2_score(test, forecast)\n",
    "\n",
    "print(f\"SARIMA Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"SARIMA R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e4be795",
   "metadata": {},
   "source": [
    "Prophet Time Series Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41371a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you don't have prophet installed, run: !pip install prophet\n",
    "from prophet import Prophet\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "close_series = model_df['Close']\n",
    "\n",
    "# Prophet requires a DataFrame with columns 'ds' and 'y'\n",
    "df_prophet = close_series.reset_index()\n",
    "df_prophet.columns = ['ds', 'y']\n",
    "\n",
    "# Ensure 'ds' is datetime and daily frequency\n",
    "if not np.issubdtype(df_prophet['ds'].dtype, np.datetime64):\n",
    "    df_prophet['ds'] = pd.to_datetime(df_prophet['ds'])\n",
    "df_prophet = df_prophet.sort_values('ds')\n",
    "df_prophet = df_prophet.set_index('ds').asfreq('D').reset_index()\n",
    "\n",
    "# Fill missing values (Prophet cannot handle NaN)\n",
    "df_prophet['y'] = df_prophet['y'].interpolate(method='linear').fillna(method='bfill').fillna(method='ffill')\n",
    "\n",
    "# Split into train and test sets\n",
    "split_idx = int(len(df_prophet) * 0.8)\n",
    "train, test = df_prophet.iloc[:split_idx], df_prophet.iloc[split_idx:]\n",
    "\n",
    "model = Prophet()\n",
    "model.fit(train)\n",
    "\n",
    "future = model.make_future_dataframe(periods=len(test), freq='D')\n",
    "forecast = model.predict(future)\n",
    "\n",
    "# Align forecast with test set\n",
    "y_pred = forecast['yhat'].iloc[-len(test):].values\n",
    "mse = mean_squared_error(test['y'], y_pred)\n",
    "r2 = r2_score(test['y'], y_pred)\n",
    "\n",
    "print(f\"Prophet Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Prophet R^2 Score: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab38a909",
   "metadata": {},
   "source": [
    "Ensemble Method: Averaging Predictions from Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aadbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Average predictions from Linear Regression, Random Forest, and XGBoost\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "model_df = combined_df.dropna()\n",
    "X = model_df.drop(columns=[\"Close\"])\n",
    "y = model_df[\"Close\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train models\n",
    "lr = LinearRegression().fit(X_train, y_train)\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42).fit(X_train, y_train)\n",
    "xgb = XGBRegressor(n_estimators=100, random_state=42, verbosity=0).fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_lr = lr.predict(X_test)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "# Ensemble: simple average\n",
    "y_pred_ensemble = (y_pred_lr + y_pred_rf + y_pred_xgb) / 3\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_ensemble)\n",
    "r2 = r2_score(y_test, y_pred_ensemble)\n",
    "\n",
    "print(f\"Ensemble Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Ensemble R^2 Score: {r2:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
